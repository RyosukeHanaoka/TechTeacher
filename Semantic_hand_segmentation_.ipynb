{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPTuCeHNddtVlvXEGdU36jg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RyosukeHanaoka/TechTeacher/blob/main/Semantic_hand_segmentation_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Pytorch ã‚’ä½¿ç”¨ã—ãŸã€æ‰‹ã®ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³\n",
        "ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã€ç”»åƒå†…ã®å„ãƒ”ã‚¯ã‚»ãƒ«ã®ã‚¯ãƒ©ã‚¹ã‚’äºˆæ¸¬ã™ã‚‹ã‚¿ã‚¹ã‚¯ã§ã™ã€‚ã“ã®å•é¡Œã¯ã€ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å‘¨å›²ã®ãƒœãƒƒã‚¯ã‚¹ã‚’äºˆæ¸¬ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ¤œå‡ºã‚ˆã‚Šã‚‚å›°é›£ã§ã™ã€‚ã“ã‚Œã¯ã€å„ãƒ”ã‚¯ã‚»ãƒ«ã®ã‚¯ãƒ©ã‚¹ã‚’äºˆæ¸¬ã™ã‚‹ã ã‘ã§ãªãã€åŒã˜ã‚¯ãƒ©ã‚¹ã®è¤‡æ•°ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’åŒºåˆ¥ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚ˆã‚Šã‚‚ã‚ãšã‹ã«ç°¡å˜ã§ã™ã€‚ä¸‹ã®å›³ã¯ã€å–å¾—ã—ã‚ˆã†ã¨ã—ã¦ã„ã‚‹çµæœã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚\n",
        "\n",
        "ã“ã“ã§ã¯ã€Pytorch ã¨ãã®äº‹å‰å®šç¾©ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã€æ‰‹æ—©ãç°¡å˜ã«æ‰‹ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚’ç«‹ã¡ä¸Šã’ã¦å®Ÿè¡Œã—ã¦ã¿ã¾ã™ã€‚\n",
        "\n",
        "ç‹¬è‡ªã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ« ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’è¨­è¨ˆã™ã‚‹ã®ã§ã¯ãªãã€Pytorch ã®ãƒ¢ãƒ‡ãƒ« ãƒªãƒã‚¸ãƒˆãƒªã‹ã‚‰Resnet50 ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ã‚’å‚™ãˆãŸ DeepLabv3ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚æ¬¡ã«ã€EGO Hands[2]ã€GTEA[3]ã€Hand over Face[1]ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§æ§‹æˆã•ã‚Œã‚‹çµåˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¾ã™ã€‚ã“ã‚Œã¯ã€ç´„ 28,000 å€‹ã®ç”»åƒã¨ãã®ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ ãƒã‚¹ã‚¯ (2.1 GB ã®ãƒ‡ãƒ¼ã‚¿) ã‚’æ§‹æˆã—ã¾ã™ã€‚æœ€å¾Œã«ã€OpenCV ã‚’ä½¿ç”¨ã—ã¦ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§æ‰‹ã‚’ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåŒ–ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ã„ãã¤ã‹ã®é–¢æ•°ã‚’ä½œæˆã—ã¾ã™ã€‚"
      ],
      "metadata": {
        "id": "DeKEj2Xkr-Nd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ãƒ¢ãƒ‡ãƒ«\n",
        "æœ€åˆã®ã‚¹ãƒ†ãƒƒãƒ—ã¯ã€Pytorch ã®ãƒªãƒã‚¸ãƒˆãƒªã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—ã™ã‚‹ã“ã¨ã§ã™ã€‚ã“ã‚Œã¯éå¸¸ã«ç°¡å˜ã§ã™ã€‚"
      ],
      "metadata": {
        "id": "6Mly7Zy8sJJu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Oiw4NraKq5Mz"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "deeplab = models.segmentation.deeplabv3_resnet50(pretrained=0,\n",
        "                                                 progress=1,\n",
        "                                                 num_classes=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ã“ã“ã§ã¯ã€torchvision ã®ãƒ¢ãƒ‡ãƒ« ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦deeplabv3_resnet50ãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—ã—ã¾ã™ã€‚2 ã¤ã®ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ç”»åƒã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã€ã‚¯ãƒ©ã‚¹ã®æ•°ã‚’num_classes2 ã¨ã—ã¦æŒ‡å®šã—ã¾ã™ã€‚1 ã¤ã¯æ‰‹ã®ã‚ã‚‹é ˜åŸŸã‚’äºˆæ¸¬ã™ã‚‹ãŸã‚ã€ã‚‚ã† 1 ã¤ã¯æ‰‹ã®ãªã„é ˜åŸŸã‚’äºˆæ¸¬ã™ã‚‹ãŸã‚ã§ã™ã€‚ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ç”»åƒã¯å…¥åŠ›ç”»åƒã¨åŒã˜ã‚µã‚¤ã‚ºã«ãªã‚Šã¾ã™ã€‚ã“ã‚Œã‚‰ 2 ã¤ã®äºˆæ¸¬ã‚’æ¯”è¼ƒã—ã¦ã€ãƒ¢ãƒ‡ãƒ«ãŒç”»åƒã®å„ãƒ”ã‚¯ã‚»ãƒ«ã§ãƒãƒ³ãƒ‰ã®å¯èƒ½æ€§ãŒé«˜ã„ã‹ã€ãƒãƒ³ãƒ‰ãŒå­˜åœ¨ã—ãªã„ã‹ã‚’äºˆæ¸¬ã™ã‚‹ã‹ã‚’ç¢ºèªã—ã¾ã™ã€‚"
      ],
      "metadata": {
        "id": "w9lldJtTsOWQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "æ¬¡ã«ã€ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã™ã‚‹ãŸã‚ã®ã‚«ã‚¹ã‚¿ãƒ  ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã—ã¾ã™ã€‚"
      ],
      "metadata": {
        "id": "pDvaglaosbFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HandSegModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(HandSegModel,self).__init__()\n",
        "        self.dl = deeplab\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.dl(x)['out']\n",
        "        return y"
      ],
      "metadata": {
        "id": "Lfqn7TRjq-Lm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ãƒ¢ãƒ‡ãƒ«ã«é–¢ã—ã¦è¡Œã†ã¹ãã“ã¨ã¯ã“ã‚Œã ã‘ã§ã™ã€‚"
      ],
      "metadata": {
        "id": "ik4lRneVshco"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ãƒ‡ãƒ¼ã‚¿ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼\n",
        "æ¬¡ã«ã€ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã“ã®ãƒªãƒ³ã‚¯ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã§ãã¾ã™ã€‚ãƒ•ã‚©ãƒ«ãƒ€ãƒ¼ã«ã¯ 3 ã¤ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒã‚ã‚Šã¾ã™ã€‚ä½¿ç”¨ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ•ã‚©ãƒ«ãƒ€ãƒ¼ã‚’ã€Python ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã™ã‚‹ãƒ•ã‚©ãƒ«ãƒ€ãƒ¼ã«é…ç½®ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã‚ã‚‹ã„ã¯ã€ç‹¬è‡ªã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚ğŸ˜…\n",
        "\n",
        "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã—ã€Pytorch ã®ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’ä½¿ç”¨ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰ãƒãƒƒãƒã‚’ãƒ•ã‚§ãƒƒãƒã—ã¾ã™ã€‚ã“ã‚ŒãŒã‚«ã‚¹ã‚¿ãƒ  ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã™ã€‚"
      ],
      "metadata": {
        "id": "pD_vY23HsnOj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class SegDataset(Dataset):\n",
        "\n",
        "    def __init__(self, parentDir, imageDir, maskDir):\n",
        "        self.imageList = glob.glob(parentDir+'/'+imageDir+'/*')\n",
        "        self.imageList.sort()\n",
        "        self.maskList = glob.glob(parentDir+'/'+maskDir+'/*')\n",
        "        self.maskList.sort()\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        preprocess = transforms.Compose([\n",
        "                                    transforms.Resize((384,288), 2),\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
        "\n",
        "        X = Image.open(self.imageList[index]).convert('RGB')\n",
        "        X = preprocess(X)\n",
        "\n",
        "        trfresize = transforms.Resize((384, 288), 2)\n",
        "        trftensor = transforms.ToTensor()\n",
        "\n",
        "        yimg = Image.open(self.maskList[index]).convert('L')\n",
        "        y1 = trftensor(trfresize(yimg))\n",
        "        y1 = y1.type(torch.BoolTensor)\n",
        "        y2 = torch.bitwise_not(y1)\n",
        "        y = torch.cat([y2, y1], dim=0)\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imageList)"
      ],
      "metadata": {
        "id": "EfIoLoXjrC9y"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ãƒã‚¹ã‚¯ã¨ç”»åƒãŒåˆ¥ã®ãƒ•ã‚©ãƒ«ãƒ€ãƒ¼ã«ã‚ã‚Šã€ãã‚Œã‚‰ã®ãƒ•ã‚©ãƒ«ãƒ€ãƒ¼ãŒåŒã˜è¦ªãƒ•ã‚©ãƒ«ãƒ€ãƒ¼ã«ã‚ã‚‹ã¨ä»®å®šã—ã¾ã™ã€‚\n",
        "ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿ãƒ¼ã¯ 3 ã¤ã®å¼•æ•°ã‚’å–ã‚Šã¾ã™ã€‚\n",
        "\n",
        "parentDir: ã‚¤ãƒ¡ãƒ¼ã‚¸ãŠã‚ˆã³ãƒã‚¹ã‚¯ ãƒ•ã‚©ãƒ«ãƒ€ãƒ¼ãŒé…ç½®ã•ã‚Œã‚‹è¦ªãƒ•ã‚©ãƒ«ãƒ€ãƒ¼ã®åå‰ã€‚\n",
        "imageDir: ç”»åƒãŒé…ç½®ã•ã‚Œã¦ã„ã‚‹ãƒ•ã‚©ãƒ«ãƒ€ãƒ¼ã€‚\n",
        "MaskDir: ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ ãƒã‚¹ã‚¯ãŒé…ç½®ã•ã‚Œã¦ã„ã‚‹ãƒ•ã‚©ãƒ«ãƒ€ãƒ¼ã€‚\n",
        "ã‚¯ãƒ©ã‚¹ã®ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿ãƒ¼ã§ã€SegDatasetã‚¤ãƒ¡ãƒ¼ã‚¸ã¨ãƒã‚¹ã‚¯ã®ãƒ•ã‚¡ã‚¤ãƒ«åã®ãƒªã‚¹ãƒˆã‚’å–å¾—ã—ã¾ã™ã€‚ã“ã®__getitem__ é–¢æ•°ã§ã¯ã€ç”»åƒã¨ãƒã‚¹ã‚¯ã®ä¸¡æ–¹ã‚’å–å¾—ã—ã¾ã™ã€‚ç”»åƒã®ã‚µã‚¤ã‚ºã‚’å¤‰æ›´ã—ã¦æ¨™æº–åŒ–ã—ã€X ã‚’å–å¾—ã—ã¾ã™ã€‚ãƒ©ãƒ™ãƒ«ã§ã‚‚ã‚ã‚‹ãƒã‚¹ã‚¯ã«ã¤ã„ã¦ã¯ã€ç”»åƒã®ã‚µã‚¤ã‚ºã‚’å¤‰æ›´ã—ã¦æ¨™æº–åŒ–ã—ã¾ã™ã€‚ãã®å¾Œã€__bitwisenot__ãƒã‚¹ã‚¯ã«æ“ä½œã‚’é©ç”¨ã—ã¦ã€å…ƒã®ãƒã‚¹ã‚¯ã®æ­£ç¢ºãªãƒã‚¬ã§ã‚ã‚‹åˆ¥ã®ãƒã‚¹ã‚¯ã‚’å–å¾—ã—ã¾ã™ã€‚æ¬¡ã«ã€ã“ã‚Œã‚‰ 2 ã¤ã®ãƒã‚¹ã‚¯ã‚’ã‚¹ã‚¿ãƒƒã‚¯ã—ã¦ 2 ãƒãƒ£ãƒãƒ« ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’å–å¾—ã—ã¾ã™ã€‚æœ€åˆã®ãƒãƒ£ãƒãƒ«ã¯ãƒãƒ³ãƒ‰ ãƒ©ãƒ™ãƒ«ã«å¯¾å¿œã—ã€2 ç•ªç›®ã®ãƒãƒ£ãƒãƒ«ã¯ãƒãƒ¼ãƒãƒ³ãƒ‰ ãƒ©ãƒ™ãƒ«ã«å¯¾å¿œã—ã¾ã™ã€‚\n",
        "\n",
        "è¤‡æ•°ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ 1 ã¤ã«çµåˆã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã“ã‚ŒãŒç§ãŒã‚„ã£ãŸæ–¹æ³•ã§ã™ã€‚"
      ],
      "metadata": {
        "id": "QWUr0dgCsxoz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import ConcatDataset\n",
        "\n",
        "EGOdataset = SegDataset('egodata', 'images', 'masks')\n",
        "HOFdataset = SegDataset('hand_over_face', 'images_resized', 'masks')\n",
        "GTEAdataset = SegDataset('GTEAhands', 'Images', 'Masks')\n",
        "\n",
        "megaDataset = ConcatDataset([EGOdataset, HOFdataset, GTEAdataset])"
      ],
      "metadata": {
        "id": "1NtLTtFVrHfW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ãã‚Œãã‚Œã«å¯¾ã—ã¦ SegDataset ã‚’ä½œæˆã—ã€ãã‚Œã‚‰ã‚’ .html ã¨ã—ã¦çµåˆã—ã¾ã™megaDataset ğŸ’ªã€‚æ¬¡ã«ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’åˆ†å‰²ã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚° ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”¨ã« 2 ã¤ã®ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’ä½œæˆã—ã¾ã™ã€‚"
      ],
      "metadata": {
        "id": "fwZ_78ZStD67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "#TTR is Train Test Ratio\n",
        "def trainTestSplit(dataset, TTR):\n",
        "    trainDataset = torch.utils.data.Subset(dataset, range(0, int(TTR * len(dataset))))\n",
        "    valDataset = torch.utils.data.Subset(dataset, range(int(TTR*len(dataset)), len(dataset)))\n",
        "    return trainDataset, valDataset\n",
        "\n",
        "batchSize = 2\n",
        "trainDataset, valDataset = trainTestSplit(megaDataset, 0.9)\n",
        "trainLoader = DataLoader(trainDataset, batch_size = batchSize, shuffle=True, drop_last=True)\n",
        "valLoader = DataLoader(valDataset, batch_size = batchSize, shuffle=True, drop_last=True)\n",
        "\n",
        "def trainTestSplit(dataset, TTR):\n",
        "    trainDataset = torch.utils.data.Subset(dataset, range(0, int(TTR * len(dataset))))\n",
        "    valDataset = torch.utils.data.Subset(dataset, range(int(TTR*len(dataset)), len(dataset)))\n",
        "    return trainDataset, valDataset\n",
        "\n",
        "batchSize = 2\n",
        "trainDataset, valDataset = trainTestSplit(megaDataset, 0.9)\n",
        "trainLoader = DataLoader(trainDataset, batch_size = batchSize, shuffle=True, drop_last=True)\n",
        "valLoader = DataLoader(valDataset, batch_size = batchSize, shuffle=True, drop_last=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "2kImoLV3rMx7",
        "outputId": "22d909ad-082a-437c-879e-5934ed3aa3cf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-80ffcb3d41c0>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mbatchSize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtrainDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalDataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainTestSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmegaDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrainLoader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatchSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mvalLoader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatchSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# map-style\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             raise ValueError(\"num_samples should be a positive integer \"\n\u001b[0m\u001b[1;32m    108\u001b[0m                              \"value, but got num_samples={}\".format(self.num_samples))\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(megaDataset))\n",
        "print(EGOdataset.imageList[:5])  # æœ€åˆã®5ã¤ã®ç”»åƒã®ãƒ‘ã‚¹ã‚’è¡¨ç¤º\n",
        "print(EGOdataset.maskList[:5])   # æœ€åˆã®5ã¤ã®ãƒã‚¹ã‚¯ã®ãƒ‘ã‚¹ã‚’è¡¨ç¤º"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pivIY-I1pja",
        "outputId": "e0ba0299-c11f-4059-ec09-baadffaf1313"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "[]\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ãƒ”ã‚¯ã‚»ãƒ«ç²¾åº¦ã¯ã€æ­£ã—ãäºˆæ¸¬ã•ã‚ŒãŸãƒ”ã‚¯ã‚»ãƒ«ã®æ•°ã‚’ãƒ”ã‚¯ã‚»ãƒ«ã®ç·æ•°ã§å‰²ã£ãŸã‚‚ã®ã§ã™ã€‚"
      ],
      "metadata": {
        "id": "4r5qV4EXtNRq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™\n",
        "ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã®æº–å‚™ãŒã§ããŸã®ã§ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚° ãƒ—ãƒ­ã‚»ã‚¹ã‚’è¿½è·¡ã™ã‚‹ãŸã‚ã«ã„ãã¤ã‹ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ä½œæˆã—ã¾ã™ã€‚\n",
        "\n",
        "ã“ã®ã‚¿ã‚¹ã‚¯ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¨ã—ã¦ã€Intersection over Unionã¨Pixel Accuracyã‚’ä½¿ç”¨ã—ã¾ã™ã€‚IOU ã¯ã€ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ ã‚¿ã‚¹ã‚¯ã®æ¨™æº–ãƒ¡ãƒˆãƒªãƒƒã‚¯ã§ã™ã€‚äºˆæ¸¬ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®äº¤å·®é¢ç©ã‚’ãã‚Œã‚‰ã®çµåˆã§å‰²ã£ãŸå€¤ãŒå¾—ã‚‰ã‚Œã¾ã™ã€‚ç›´è¦³çš„ã«ã¯ã€æ­£ã—ãäºˆæ¸¬ã•ã‚ŒãŸé ˜åŸŸã®é¢ç©ã‚’é–¢é€£ã™ã‚‹åˆè¨ˆé¢ç©ã§å‰²ã£ãŸã‚‚ã®ã¨è€ƒãˆã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚æ•°å€¤çš„ã«ã¯ã€0.5 ã‚’è¶…ãˆã‚‹ IOU å€¤ãŒé©åˆ‡ã§ã™ã€‚é ã‘ã‚Œã°é ã„ã»ã©è‰¯ã„ã§ã™ã€‚"
      ],
      "metadata": {
        "id": "zcNzGlNXtSNf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def meanIOU(target, predicted):\n",
        "    if target.shape != predicted.shape:\n",
        "        print(\"target has dimension\", target.shape, \", predicted values have shape\", predicted.shape)\n",
        "        return\n",
        "\n",
        "    if target.dim() != 4:\n",
        "        print(\"target has dim\", target.dim(), \", Must be 4.\")\n",
        "        return\n",
        "\n",
        "    iousum = 0\n",
        "    for i in range(target.shape[0]):\n",
        "        target_arr = target[i, :, :, :].clone().detach().cpu().numpy().argmax(0)\n",
        "        predicted_arr = predicted[i, :, :, :].clone().detach().cpu().numpy().argmax(0)\n",
        "\n",
        "        intersection = np.logical_and(target_arr, predicted_arr).sum()\n",
        "        union = np.logical_or(target_arr, predicted_arr).sum()\n",
        "        if union == 0:\n",
        "            iou_score = 0\n",
        "        else :\n",
        "            iou_score = intersection / union\n",
        "        iousum +=iou_score\n",
        "\n",
        "    miou = iousum/target.shape[0]\n",
        "    return miou"
      ],
      "metadata": {
        "id": "m_lf5jkgrSYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ãƒ”ã‚¯ã‚»ãƒ«ç²¾åº¦ã¯ã€æ­£ã—ãäºˆæ¸¬ã•ã‚ŒãŸãƒ”ã‚¯ã‚»ãƒ«ã®æ•°ã‚’ãƒ”ã‚¯ã‚»ãƒ«ã®ç·æ•°ã§å‰²ã£ãŸã‚‚ã®ã§ã™ã€‚"
      ],
      "metadata": {
        "id": "33BDSGmItkAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pixelAcc(target, predicted):\n",
        "    if target.shape != predicted.shape:\n",
        "        print(\"target has dimension\", target.shape, \", predicted values have shape\", predicted.shape)\n",
        "        return\n",
        "\n",
        "    if target.dim() != 4:\n",
        "        print(\"target has dim\", target.dim(), \", Must be 4.\")\n",
        "        return\n",
        "\n",
        "    accsum=0\n",
        "    for i in range(target.shape[0]):\n",
        "        target_arr = target[i, :, :, :].clone().detach().cpu().numpy().argmax(0)\n",
        "        predicted_arr = predicted[i, :, :, :].clone().detach().cpu().numpy().argmax(0)\n",
        "\n",
        "        same = (target_arr == predicted_arr).sum()\n",
        "        a, b = target_arr.shape\n",
        "        total = a*b\n",
        "        accsum += same/total\n",
        "\n",
        "    pixelAccuracy = accsum/target.shape[0]\n",
        "    return pixelAccuracy"
      ],
      "metadata": {
        "id": "pBkHcEYsrVy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°\n",
        "ã•ã¦ã€ç§ãŸã¡å…¨å“¡ãŒå¾…ã¡æœ›ã‚“ã§ã„ãŸãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®ç¬é–“ã§ã™ã€‚\n",
        "\n",
        "ã¾ãšã€é©åˆ‡ãªãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦ã€ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã¨æå¤±é–¢æ•°ã€ãƒ¢ãƒ‡ãƒ«ã€å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ© ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆã—ã¾ã™ã€‚"
      ],
      "metadata": {
        "id": "JCUY-sBQteJu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = HandSegModel()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.00005)\n",
        "loss_fn = nn.BCEWithLogitsLoss ()\n",
        "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=0.8)"
      ],
      "metadata": {
        "id": "Pq-UNt9irY7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "æ¬¡ã«ã€ä½œæˆã•ã‚ŒãŸã™ã¹ã¦ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å¼•æ•°ã¨ã—ã¦å—ã‘å–ã‚Šã€ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚° ãƒ«ãƒ¼ãƒ—é–¢æ•°ã‚’ä½œæˆã—ã¾ã™ã€‚"
      ],
      "metadata": {
        "id": "BwTzs5jsunFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(n_epochs, optimizer, lr_scheduler, model, loss_fn, train_loader, val_loader, lastCkptPath = None):\n",
        "    if torch.cuda.is_available():\n",
        "        dev = \"cuda:0\"\n",
        "    else:\n",
        "        dev = \"cpu\"\n",
        "    device = torch.device(dev)\n",
        "\n",
        "    tr_loss_arr = []\n",
        "    val_loss_arr = []\n",
        "    meanioutrain = []\n",
        "    pixelacctrain = []\n",
        "    meanioutest = []\n",
        "    pixelacctest = []\n",
        "    prevEpoch = 0\n",
        "\n",
        "    if lastCkptPath != None :\n",
        "        checkpoint = torch.load(lastCkptPath)\n",
        "        prevEpoch = checkpoint['epoch']model.load_state_dict(checkpoint['state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])for state in optimizer.state.values():\n",
        "            for k, v in state.items():\n",
        "                if isinstance(v, torch.Tensor):\n",
        "                    state[k] = v.to(device)tr_loss_arr =  checkpoint['Training Loss']\n",
        "        val_loss_arr =  checkpoint['Validation Loss']\n",
        "        meanioutrain =  checkpoint['MeanIOU train']\n",
        "        pixelacctrain =  checkpoint['PixelAcc train']\n",
        "        meanioutest =  checkpoint['MeanIOU test']\n",
        "        pixelacctest =  checkpoint['PixelAcc test']\n",
        "        print(\"loaded model, \", checkpoint['description'], \"at epoch\", prevEpoch)model.to(device)\n",
        "\n",
        "    for epoch in range(0, n_epochs):\n",
        "        train_loss = 0.0\n",
        "        pixelacc = 0\n",
        "        meaniou = 0\n",
        "\n",
        "        pbar = tqdm(train_loader, total = len(train_loader))\n",
        "        for X, y in pbar:\n",
        "            torch.cuda.empty_cache()\n",
        "            model.train()\n",
        "            X = X.to(device).float()\n",
        "            y = y.to(device).float()\n",
        "            ypred = model(X)\n",
        "            loss = loss_fn(ypred, y)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            tr_loss_arr.append(loss.item())\n",
        "            meanioutrain.append(meanIOU(y, ypred))\n",
        "            pixelacctrain.append(pixelAcc(y, ypred))\n",
        "            pbar.set_postfix({'Epoch':epoch+1+prevEpoch,\n",
        "                              'Training Loss': np.mean(tr_loss_arr),\n",
        "                              'Mean IOU': np.mean(meanioutrain),\n",
        "                              'Pixel Acc': np.mean(pixelacctrain)\n",
        "                             })\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            val_loss = 0\n",
        "            pbar = tqdm(val_loader, total = len(val_loader))\n",
        "            for X, y in pbar:\n",
        "                torch.cuda.empty_cache()\n",
        "                X = X.to(device).float()\n",
        "                y = y.to(device).float()\n",
        "                model.eval()\n",
        "                ypred = model(X)\n",
        "\n",
        "                val_loss_arr.append(loss_fn(ypred, y).item())\n",
        "                pixelacctest.append(pixelAcc(y, ypred))\n",
        "                meanioutest.append(meanIOU(y, ypred))\n",
        "\n",
        "                pbar.set_postfix({'Epoch':epoch+1+prevEpoch,\n",
        "                                  'Validation Loss': np.mean(val_loss_arr),\n",
        "                                  'Mean IOU': np.mean(meanioutest),\n",
        "                                  'Pixel Acc': np.mean(pixelacctest)\n",
        "                                 })\n",
        "\n",
        "\n",
        "\n",
        "        checkpoint = {\n",
        "            'epoch':epoch+1+prevEpoch,\n",
        "            'description':\"add your description\",\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'Training Loss': tr_loss_arr,\n",
        "            'Validation Loss':val_loss_arr,\n",
        "            'MeanIOU train':meanioutrain,\n",
        "            'PixelAcc train':pixelacctrain,\n",
        "            'MeanIOU test':meanioutest,\n",
        "            'PixelAcc test':pixelacctest\n",
        "        }\n",
        "        torch.save(checkpoint, 'checkpoints/checkpointhandseg'+str(epoch+1+prevEpoch)+'.pt')\n",
        "        lr_scheduler.step()\n",
        "\n",
        "    return tr_loss_arr, val_loss_arr, meanioutrain, pixelacctrain, meanioutest, pixelacctest"
      ],
      "metadata": {
        "id": "Zc23A_Lrrgvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã®å¹³å‡æå¤±ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚ã‚¨ãƒãƒƒã‚¯ã”ã¨ã«ã€ã“ã‚Œã¾ã§ã«è¨ˆç®—ã•ã‚ŒãŸã™ã¹ã¦ã®æå¤±ã¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å«ã‚€ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãŒä¿å­˜ã•ã‚Œã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ã„ã¤ã§ã‚‚ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’åœæ­¢ã—ã€ãƒ‡ãƒ¼ã‚¿ã‚’å¤±ã†ã“ã¨ãªãå†é–‹ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚ã“ã®é–¢æ•°ã®æœ€å¾Œã®å¼•æ•°ã¯ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å†é–‹ã™ã‚‹ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã¸ã®ãƒ‘ã‚¹ã§ã™ã€‚ã“ã®é–¢æ•°ã¯ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‹ã‚‰ã®ã™ã¹ã¦ã®é‡è¦ãªãƒ‡ãƒ¼ã‚¿ã€ã¤ã¾ã‚Šãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŠã‚ˆã³æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä¸Šã®æå¤±ã¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ã‚¿ãƒ—ãƒ«ã‚’è¿”ã—ã¾ã™ã€‚\n",
        "\n",
        "ã¾ãšã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚° ãƒ«ãƒ¼ãƒ—ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚"
      ],
      "metadata": {
        "id": "lxkZ3hbiu23r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#call the training loop,\n",
        "#make sure to pass correct checkpoint path, or none if starting with the training\n",
        "\n",
        "retval = training_loop(3,\n",
        "                       optimizer,\n",
        "                       lr_scheduler,\n",
        "                       model,\n",
        "                       loss_fn,\n",
        "                       trainLoader,\n",
        "                       valLoader,\n",
        "                       'checkpoints/checkpointhandseg.pt')"
      ],
      "metadata": {
        "id": "K3e2-wf-rk8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ—ãƒ­ãƒƒãƒˆã™ã‚‹ã«ã¯ã€ãƒªã‚¹ãƒˆã®ç§»å‹•å¹³å‡ã‚’ä½¿ç”¨ã§ãã¾ã™ã€‚"
      ],
      "metadata": {
        "id": "tUyxgbxSu9Sb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#after the training loop returns, we can plot the data\n",
        "def running_mean(x, N):\n",
        "    cumsum = np.cumsum(np.insert(x, 0, 0))\n",
        "    return (cumsum[N:] - cumsum[:-N]) / float(N)\n",
        "\n",
        "fig, ax = plt.subplots(ncols = 3, nrows = 2, figsize = (20,10))\n",
        "N = 1000\n",
        "ax[0][0].plot(running_mean(retval[0], N), 'r.', label='training loss')\n",
        "ax[1][0].plot(running_mean(retval[1], N), 'b.', label='validation loss')\n",
        "ax[0][1].plot(running_mean(retval[2], N), 'g.', label='meanIOU training')\n",
        "ax[1][1].plot(running_mean(retval[4], N), 'r.', label='meanIOU validation')\n",
        "ax[0][2].plot(running_mean(retval[3], N), 'b.', label='pixelAcc  training')\n",
        "ax[1][2].plot(running_mean(retval[5], N), 'b.', label='pixelAcc validation')\n",
        "for i in ax:\n",
        "    for j in i:\n",
        "        j.legend()\n",
        "        j.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PPyCfaNLrolG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "N å€¤ã‚’å°‘ã—èª¿æ•´ã—ã¦ã€ã‚ˆã‚Šæ»‘ã‚‰ã‹ãªã€ã¾ãŸã¯ã‚ˆã‚Šãƒã‚¤ã‚ºã®å¤šã„ãƒ—ãƒ­ãƒƒãƒˆã‚’å–å¾—ã—ã¦ã¿ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚"
      ],
      "metadata": {
        "id": "BpM_oyKXvGwh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã®æ‰‹ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³\n",
        "ç§ãŸã¡ã¯è‡ªåˆ†ãŸã¡ã®åŠªåŠ›ã®çµæœã‚’è¦‹ã‚‹æº–å‚™ãŒã§ãã¦ã„ã¾ã™ã€‚OpenCV ã‚’ä½¿ç”¨ã—ã¦ã‚«ãƒ¡ãƒ©ã‹ã‚‰ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’èª­ã¿å–ã‚Šã€ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ ãƒã‚¹ã‚¯ã‚’äºˆæ¸¬ã—ã¾ã™ã€‚\n",
        "\n",
        "ã¾ãšã€ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰äºˆæ¸¬ã‚’å–å¾—ã™ã‚‹ãŸã‚ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ã‚’ã„ãã¤ã‹ä½œæˆã—ã¾ã™ã€‚"
      ],
      "metadata": {
        "id": "LphtggN9vIvM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#can pass np array or path to image file\n",
        "def SegmentHands(pathtest):\n",
        "\n",
        "    if isinstance(pathtest, np.ndarray):\n",
        "        img = Image.fromarray(pathtest)\n",
        "    else :\n",
        "        img = Image.open(pathtest)\n",
        "\n",
        "    preprocess = transforms.Compose([transforms.Resize((288, 384), 2),\n",
        "                                     transforms.ToTensor(),\n",
        "                                     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
        "    Xtest = preprocess(img)\n",
        "\n",
        "    checkpoint = torch.load('checkpoints/checkpointhandseg7.pt')\n",
        "    model = HandSegModel()\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        if torch.cuda.is_available():\n",
        "            dev = \"cuda:0\"\n",
        "        else:\n",
        "            dev = \"cpu\"\n",
        "        device = torch.device(dev)\n",
        "        model.to(device)\n",
        "        Xtest = Xtest.to(device).float()\n",
        "        ytest = model(Xtest.unsqueeze(0).float())\n",
        "        ypos = ytest[0, 1, :, :].clone().detach().cpu().numpy()\n",
        "        yneg = ytest[0, 0, :, :].clone().detach().cpu().numpy()\n",
        "        ytest = ypos >= yneg\n",
        "\n",
        "    mask = ytest.astype('float32')\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5))\n",
        "    mask = cv2.dilate(mask,kernel,iterations = 2)\n",
        "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
        "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
        "    return mask"
      ],
      "metadata": {
        "id": "bal4oxOErst7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ã“ã®é–¢æ•°ã¯ãƒã‚¤ãƒŠãƒªãƒã‚¹ã‚¯ã‚’å‡ºåŠ›ã—ã¾ã™ã€‚å…¥åŠ›ã¨ã—ã¦ç”»åƒã® numpy é…åˆ—ã¾ãŸã¯ç”»åƒã®ãƒ‘ã‚¹ã‚’å—ã‘å–ã‚Šã¾ã™ã€‚ç”»åƒã«é–‰ã˜ã‚‹æ“ä½œã¨é–‹ãæ“ä½œã‚’é©ç”¨ã—ã¦ã€ãƒã‚¤ã‚ºã‚’è»½æ¸›ã—ã€ãƒã‚¹ã‚¯ã‚’å°‘ã—æ‹¡å¼µã—ã¾ã™ã€‚\n",
        "\n",
        "æ¬¡ã«ã€ç”»åƒå†…ã®æ‰‹ã®é ˜åŸŸã«é‡ã¿ä»˜ã‘ã•ã‚ŒãŸç·‘è‰²ã®ãƒã‚¹ã‚¯ã‚’è¿½åŠ ã™ã‚‹é–¢æ•°ãŒã„ãã¤ã‹ã‚ã‚Šã¾ã™ã€‚"
      ],
      "metadata": {
        "id": "pSwSy3sFvSM5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getcoloredMask(image, mask):\n",
        "    color_mask = np.zeros_like(image)\n",
        "    color_mask[:, :, 1] += mask.astype('uint8') * 250\n",
        "    masked = cv2.addWeighted(image, 1.0, color_mask, 1.0, 0.0)\n",
        "    return masked"
      ],
      "metadata": {
        "id": "KAgZTXn8rv03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "æœ€å¾Œã«ã€OpenCV ã‚’ä½¿ç”¨ã—ã¦ã‚«ãƒ¡ãƒ©ã‹ã‚‰ç”»åƒã‚’èª­ã¿å–ã‚Šã€ç”»åƒå†…ã®æ‰‹ã®é ˜åŸŸã‚’äºˆæ¸¬ã—ã¾ã™ã€‚"
      ],
      "metadata": {
        "id": "ZObybbMuvbW5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture(0)\n",
        "i = 0\n",
        "while(True):\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    frame = cv2.resize(frame, (384,288))\n",
        "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    if i%5 == 0:\n",
        "        i=0\n",
        "        mask = SegmentHands(rgb)\n",
        "        colmask = getcoloredMask(frame, mask)\n",
        "\n",
        "    cv2.imshow('color', np.hstack((frame, colmask)))\n",
        "    key = cv2.waitKey(24)\n",
        "    if key & 0xFF == ord('q'):\n",
        "        break\n",
        "    i+=1\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "eey7PUv7r05H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ãã®ä»–ã«è©¦ã—ã¦ã¿ã‚‹ã“ã¨:\n",
        "\n",
        "ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µï¼ˆãƒ©ãƒ³ãƒ€ãƒ  ã‚¯ãƒ­ãƒƒãƒ”ãƒ³ã‚°ã€ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã€ãƒã‚¤ã‚ºè¿½åŠ ãªã©ï¼‰ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚\n",
        "åˆ¥ã®ãƒ¢ãƒ‡ãƒ« ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ä½¿ç”¨ã™ã‚‹\n",
        "ã‚ˆã‚Šå¤§ããªã€ã¾ãŸã¯ã‚ˆã‚Šå¼·åŠ›ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã™ã‚‹\n",
        "ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª¿æ•´ã™ã‚‹"
      ],
      "metadata": {
        "id": "Yp_C7nTDvk1q"
      }
    }
  ]
}