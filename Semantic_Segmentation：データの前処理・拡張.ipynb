{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPmgy9GW0JDCnW17lHUijm1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RyosukeHanaoka/TechTeacher/blob/main/Semantic_Segmentation%EF%BC%9A%E3%83%87%E3%83%BC%E3%82%BF%E3%81%AE%E5%89%8D%E5%87%A6%E7%90%86%E3%83%BB%E6%8B%A1%E5%BC%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Semantic Segmentation：データの前処理・拡張"
      ],
      "metadata": {
        "id": "y8VD-oUloe0g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###使用するライブラリのインポート"
      ],
      "metadata": {
        "id": "FyV7CQRnosAy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tuf5FHZPoIpV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###データの前処理・拡張を設定"
      ],
      "metadata": {
        "id": "JEzv1bsro6iR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####__SegmentationDataset__\n",
        "SegmentationDatasetクラスは、PyTorchのカスタムデータセットを定義するためのものです。PyTorchのDatasetを継承しており、主に3つのメソッド(__init__, __len__, __getitem__)を実装することで、データローディングや前処理の流れをカスタマイズすることができます。\n",
        "####__init__\n",
        "image_dir: 画像ファイルが保存されているディレクトリへのパスを受け取り、インスタンス変数として保存します。\n",
        "\n",
        "mask_dir: マスクファイルが保存されているディレクトリへのパスを受け取り、インスタンス変数として保存します。\n",
        "\n",
        "transform: 画像とマスクの前処理やデータ拡張を行うための関数またはクラスのインスタンスを受け取り、インスタンス変数として保存します。デフォルトはNoneで、前処理やデータ拡張を行わない場合を意味します。\n",
        "\n",
        "self.image_list: os.listdir(image_dir)を使用して、image_dirディレクトリ内のファイル名のリストを取得し、インスタンス変数として保存します。これにより、データセット内の各画像に簡単にアクセスできるようになります。\n",
        "\n",
        "####__len__\n",
        "__len__はPythonの特殊メソッドの一つで、組み込み関数len()を対象のオブジェクトに適用したときに呼び出されるメソッドです。Datasetクラスを継承する際には、この__len__メソッドを定義する必要があります。このメソッドは、データセットの総数（つまり画像の総数）を返すように設計されています。\n",
        "\n",
        "具体的には、self.image_listにはimage_dirに存在する画像ファイルの名前のリストが格納されています。そのため、len(self.image_list)はそのディレクトリにある画像ファイルの総数を返します。\n",
        "\n",
        "この__len__メソッドのおかげで、後の処理でlen(dataset_object)のようにして、データセットのサイズ（画像の数）を簡単に取得することができます。\n",
        "\n",
        "####__getitem__\n",
        "\n",
        "os.path.join(self.image_dir, self.image_list[idx]):\n",
        "これは、指定されたディレクトリ（self.image_dir）とファイル名（self.image_list[idx]）を組み合わせて、そのファイルのフルパスを作成しています。マスクについても同様の操作をしています。\n",
        "\n",
        "Image.open(image_path).convert(\"RGB\"):\n",
        "これにより、先程作成したフルパスから画像を開き（読み込み）、RGBモードでの画像として変換します。convert(\"RGB\")は、元の画像がRGBモードでない場合や、アルファチャンネルを持っている場合にRGBモードへ変換するために使用します。マスクはモノクロームとして読み込むため、convert(\"L\")を使用しています。\n",
        "\n",
        "if self.transform::\n",
        "この部分は、前処理やデータ拡張を適用するためのものです。self.transformは初期化の際に指定されるtransform関数（または関数の組み合わせ）を保持しています。\n",
        "\n",
        "この関数は、通常、torchvision.transformsモジュールから提供される関数を使用して作成されますが、カスタムの変換関数を使用することもできます。この関数は、入力として画像とマスクを受け取り、前処理やデータ拡張を行った画像とマスクを返すように設計されていることが期待されます。\n",
        "\n",
        "この例では、self.transformがNoneでない場合（すなわち、何らかの変換関数が指定されている場合）にのみ、変換が適用されます。\n",
        "\n",
        "この__getitem__関数は、指定されたインデックス（idx）に対応する画像とマスクのペアを返すように設計されています。これにより、データローダーがバッチ単位で画像とマスクのペアを取得する際に、この関数が連続的に呼び出されます。"
      ],
      "metadata": {
        "id": "8nPk5Cu6pgCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SegmentationDataset(Dataset):\n",
        "    def __init__(self, image_dir, mask_dir, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.transform = transform#「このクラスの中で後から使えるように、transformの値をインスタンス変数に保存する」という意味\n",
        "        self.image_list = os.listdir(image_dir)\n",
        "        #この__init__メソッドは、データセットクラスがインスタンス化されるとき（例：dataset = SegmentationDataset(image_dir, mask_dir)）に一度だけ呼び出される。\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = os.path.join(self.image_dir, self.image_list[idx])\n",
        "        mask_path = os.path.join(self.mask_dir, self.image_list[idx])\n",
        "\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "        mask = Image.open(mask_path).convert(\"L\")\n",
        "\n",
        "        if self.transform:\n",
        "            image, mask = self.transform(image, mask)\n",
        "\n",
        "        return image, mask"
      ],
      "metadata": {
        "id": "kL8ygTYVoPML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###データセットクラスの作成 (画像とマスクのペアを返す)"
      ],
      "metadata": {
        "id": "TZF_5IZlpGMI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####__SegmentationTransform__\n",
        "SegmentationTransformクラスは、セマンティックセグメンテーションのデータ変換のためのカスタムクラスを初期化する部分です。\n",
        "\n",
        "####__init__\n",
        "output_size: この値は、出力される画像のサイズを指定します。多くのディープラーニングモデルでは、入力画像のサイズが一定であることが必要です。この変数を使用して、すべての画像が同じサイズにリサイズされることを保証します。\n",
        "\n",
        "meanとstd: これらは、データ正規化のための平均と標準偏差を指定します。ディープラーニングモデルの学習を効果的に行うために、入力データを正規化（平均0、標準偏差1）するのが一般的です。これらの値は、データセット全体の画像の平均と標準偏差に基づいていることが多いです。ただし、一般的な値（例：Imagenetの平均と標準偏差）を使用することもよくあります。\n",
        "\n",
        "####__call__\n",
        "transforms.Resize(self.output_size):torchvision.transformsモジュールのResizeクラスをインスタンス化しています。このインスタンス化されたクラスは、引数として与えられたサイズ（self.output_size）に画像をリサイズする機能を持っています。\n",
        "\n",
        "Horizontal Flip（水平反転）:単純なData Augmentationの手法で、50%の確率で入力画像と対応するマスクを水平方向に反転させます。このようなランダムな変換は、モデルがトレーニングデータに過剰適合するのを防ぎ、汎化性能を向上させることを目的としています。\n",
        "\n",
        "ToTensor:これにより、PIL画像（またはnumpy配列）がPyTorchのテンソルに変換されます。この変換では、画像のピクセル値が[0, 255]の範囲から[0.0, 1.0]の範囲に正規化されます。\n",
        "\n",
        "Normalization（正規化）:これにより、テンソル形式の画像が指定された平均値と標準偏差で正規化されます。これはネットワークの収束を速くし、トレーニングの安定性を向上させるための一般的な手法です。正規化する際の平均値と標準偏差は、通常、使用するデータセットの統計に基づいています。\n",
        "\n",
        "この関数の最後で、正規化された画像とマスクのテンソルが返されます。これにより、モデルのトレーニングや評価に使用できるようになります。"
      ],
      "metadata": {
        "id": "3xYdAPELsUqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SegmentationTransform:\n",
        "    def __init__(self, output_size, mean, std):\n",
        "        self.output_size = output_size\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, image, mask):\n",
        "        # Resize：#torchvision.transformsモジュールのResizeクラスをインスタンス化している。引数として与えたサイズ（self.output_size）に画像をリサイズする。\n",
        "        resize = transforms.Resize(self.output_size)#変数'resize'にリサイズ機能を持つオブジェクト'Resize'を代入している。\n",
        "        image = resize(image)#実際に画像とマスクをリサイズ\n",
        "        mask = resize(mask)#同上\n",
        "\n",
        "        # Random Horizontal Flip\n",
        "        if np.random.random() > 0.5:\n",
        "            image = transforms.functional.hflip(image)\n",
        "            mask = transforms.functional.hflip(mask)\n",
        "\n",
        "        # ToTensor & Normalize\n",
        "        image = transforms.functional.to_tensor(image)\n",
        "        mask = transforms.functional.to_tensor(mask)\n",
        "        image = transforms.functional.normalize(image, self.mean, self.std)\n",
        "\n",
        "        return image, mask.squeeze(dim=0)\n",
        "\n",
        "transform = SegmentationTransform(output_size=(384, 288), mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])"
      ],
      "metadata": {
        "id": "eCMJZkMnoXdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "mask.squeeze(dim=0)の.squeeze()メソッドは、指定された次元のサイズが1である場合に、その次元を取り除きます。\n",
        "\n",
        "例えば、テンソルの形状が[1, 512, 512]である場合（これは通常、1チャンネルのグレースケール画像を意味します）、.squeeze(dim=0)を適用すると、形状が[512, 512]のテンソルになります。\n",
        "\n",
        "このコンテキストでは、マスク画像が1つのチャンネルを持つグレースケール画像であることが期待されているため、.squeeze(dim=0)を使用して余分な次元を取り除いていると推測されます。\n",
        "\n",
        "ただし、実際にこの操作が必要かどうかは、後続の処理やモデルの設計によります。多くのニューラルネットワークはバッチ形式で画像を受け取るため、画像の形状が[B, C, H, W]（Bはバッチサイズ、Cはチャンネル数、HとWはそれぞれ高さと幅）であることを期待します。この場合、余分なチャンネル次元を取り除く必要はないかもしれません。"
      ],
      "metadata": {
        "id": "E82HQe_ewF-k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###DataLoaderの作成\n",
        "\n",
        "####ディレクトリの指定:\n",
        "\n",
        "これは、あなたのGoogle Drive内にある画像とマスクの格納場所を指定しています。your_dataset_pathは実際のデータセットのパスに置き換える必要があります。\n",
        "\n",
        "####Datasetの作成:\n",
        "\n",
        "ここでは、先程定義したSegmentationDatasetクラスを使用して、セマンティックセグメンテーションのためのデータセットを作成しています。このデータセットは、指定された変換（transform）を使用して、入力画像と対応するマスクを適切に前処理します。ここでのtransformは、SegmentationTransformクラスのインスタンスを指すものとして想定されています。\n",
        "\n",
        "####DataLoaderの作成:\n",
        "DataLoaderは、データセットからバッチを効率的に読み込むためのツールです。batch_sizeはモデルのトレーニング中に一度に処理される画像の数を指定します。shuffle=Trueは、各エポックの開始時にデータセットをシャッフルすることを意味します。これは、モデルがトレーニングデータに過剰適合するのを防ぐための一般的な手法です。\n",
        "\n",
        "要するに、このコードスニペットは、あなたのデータセットを前処理し、モデルのトレーニングや評価のためにバッチ単位でデータを供給する準備をしています。"
      ],
      "metadata": {
        "id": "-WAtPJJlpQOQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_dir = \"/content/drive/MyDrive/your_dataset_path/Images\"\n",
        "mask_dir = \"/content/drive/MyDrive/your_dataset_path/Masks\"\n",
        "dataset = SegmentationDataset(image_dir, mask_dir, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "JHZfZMjKocYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vM1uEZ_Yv895"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Dhit7t04v_S8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}