{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPNkJEBYMN/wOQ3BWivhCnv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RyosukeHanaoka/TechTeacher/blob/main/swin_with_kfold.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KTU6vo8dhP2L"
      },
      "outputs": [],
      "source": [
        "!pip install vit_pytorch timm\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "import glob\n",
        "import os\n",
        "import random\n",
        "import cv2\n",
        "import shutil\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from PIL import Image\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torch.utils.data import DataLoader, Dataset, Subset\n",
        "from torchvision import datasets, transforms\n",
        "from tqdm.notebook import tqdm\n",
        "from vit_pytorch.efficient import ViT\n",
        "from pathlib import Path\n",
        "import seaborn as sns\n",
        "import timm\n",
        "from pprint import pprint\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# シードの設定\n",
        "batch_size = 64\n",
        "epochs = 50\n",
        "lr = 0.3 * 1e-3\n",
        "gamma = 0.8\n",
        "seed = 42  # 乱数のシード\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "seed_everything(seed)\n",
        "\n",
        "# GPUの設定\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# 前処理の定義\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.RandomPerspective(distortion_scale=0.2, p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 画像のパス\n",
        "data_dir_RA = '/content/drive/MyDrive/crp>0.3/image_crp0.3_patient'\n",
        "data_dir_nonRA = '/content/drive/MyDrive/images_ra_and_nonra/image_nonra_patient'\n",
        "\n",
        "# データセットの定義\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, ra_paths, nonra_paths, transform=None):\n",
        "        self.ra_paths = ra_paths\n",
        "        self.nonra_paths = nonra_paths\n",
        "        self.transform = transform\n",
        "        self.data = self.ra_paths + self.nonra_paths\n",
        "        self.labels = [1] * len(self.ra_paths) + [0] * len(self.nonra_paths)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            img_path = self.data[idx]\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "            label = self.labels[idx]\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            return image, label\n",
        "        except UnidentifiedImageError:\n",
        "            print(f\"Couldn't read image at index {idx}: UnidentifiedImageError\")\n",
        "            # 代わりの画像を返す\n",
        "            img = Image.new('RGB', (224, 224), color='gray')\n",
        "            if self.transform:\n",
        "                img = self.transform(img)\n",
        "            label = 0  # または適切なクラスのインデックス\n",
        "            return img, label\n",
        "\n",
        "# RAとnonRAの画像パスを取得\n",
        "ra_image_paths = glob.glob(os.path.join(data_dir_RA, '*'))\n",
        "nonra_image_paths = glob.glob(os.path.join(data_dir_nonRA, '*'))\n",
        "\n",
        "# 全データセットを作成\n",
        "full_dataset = CustomDataset(ra_image_paths, nonra_image_paths, transform=None)\n",
        "\n",
        "# ラベルを取得\n",
        "labels = full_dataset.labels\n",
        "\n",
        "# Stratified K-Foldの設定\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
        "\n",
        "# 結果を記録するリスト\n",
        "all_train_acc = []\n",
        "all_val_acc = []\n",
        "all_train_loss = []\n",
        "all_val_loss = []\n",
        "\n",
        "# K-Fold Cross Validationのループ\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(full_dataset.data, labels)):\n",
        "    print(f'Fold {fold + 1}')\n",
        "    # 各フォールドのデータセットを作成\n",
        "    train_dataset = Subset(full_dataset, train_idx)\n",
        "    val_dataset = Subset(full_dataset, val_idx)\n",
        "\n",
        "    # 各フォールドのデータにトランスフォームを適用\n",
        "    train_dataset.dataset.transform = train_transforms\n",
        "    val_dataset.dataset.transform = val_transforms\n",
        "\n",
        "    # データローダーの設定\n",
        "    train_loader = DataLoader(\n",
        "        dataset=train_dataset,\n",
        "        batch_size=batch_size // 4,\n",
        "        shuffle=True,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        persistent_workers=True,\n",
        "        prefetch_factor=2\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        dataset=val_dataset,\n",
        "        batch_size=batch_size // 4,\n",
        "        shuffle=False,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        persistent_workers=True\n",
        "    )\n",
        "\n",
        "    # モデルの初期化\n",
        "    model = timm.create_model('swin_base_patch4_window7_224.ms_in1k', pretrained=True, num_classes=2)\n",
        "    model.to(device)\n",
        "\n",
        "    # 損失関数とオプティマイザ\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    scheduler = StepLR(optimizer, step_size=10, gamma=gamma)\n",
        "\n",
        "    # 訓練と評価\n",
        "    train_acc_list, val_acc_list, train_loss_list, val_loss_list = train_with_gradient_accumulation_kfold(\n",
        "        model, train_loader, val_loader, criterion, optimizer, scheduler, device, epochs\n",
        "    )\n",
        "\n",
        "    # 結果を保存\n",
        "    all_train_acc.append(train_acc_list)\n",
        "    all_val_acc.append(val_acc_list)\n",
        "    all_train_loss.append(train_loss_list)\n",
        "    all_val_loss.append(val_loss_list)\n",
        "\n",
        "# 関数の定義（K-Foldに対応）\n",
        "def train_with_gradient_accumulation_kfold(model, train_loader, val_loader, criterion, optimizer, scheduler, device, epochs):\n",
        "    accumulation_steps = 4\n",
        "    effective_batch_size = batch_size\n",
        "    actual_batch_size = effective_batch_size // accumulation_steps\n",
        "\n",
        "    train_acc_list = []\n",
        "    val_acc_list = []\n",
        "    train_loss_list = []\n",
        "    val_loss_list = []\n",
        "\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # 訓練フェーズ\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        epoch_accuracy = 0\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        for i, (data, label) in enumerate(tqdm(train_loader)):\n",
        "            with torch.cuda.amp.autocast():\n",
        "                data = data.to(device)\n",
        "                label = label.to(device)\n",
        "\n",
        "                output = model(data)\n",
        "                loss = criterion(output, label)\n",
        "                loss = loss / accumulation_steps\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            if ((i + 1) % accumulation_steps == 0) or (i + 1 == len(train_loader)):\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "            acc = (output.argmax(dim=1) == label).float().mean()\n",
        "            epoch_accuracy += acc / len(train_loader)\n",
        "            epoch_loss += loss.item() * accumulation_steps / len(train_loader)\n",
        "\n",
        "            del data, label, output, loss\n",
        "            if (i + 1) % (accumulation_steps * 2) == 0:\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "        # 検証フェーズ\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            epoch_val_accuracy = 0\n",
        "            epoch_val_loss = 0\n",
        "            for data, label in val_loader:\n",
        "                data = data.to(device)\n",
        "                label = label.to(device)\n",
        "\n",
        "                val_output = model(data)\n",
        "                val_loss = criterion(val_output, label)\n",
        "\n",
        "                acc = (val_output.argmax(dim=1) == label).float().mean()\n",
        "                epoch_val_accuracy += acc / len(val_loader)\n",
        "                epoch_val_loss += val_loss.item() / len(val_loader)\n",
        "\n",
        "                del data, label, val_output, val_loss\n",
        "\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        # 結果の記録\n",
        "        train_acc_list.append(epoch_accuracy)\n",
        "        val_acc_list.append(epoch_val_accuracy)\n",
        "        train_loss_list.append(epoch_loss)\n",
        "        val_loss_list.append(epoch_val_loss)\n",
        "\n",
        "        print(\n",
        "            f\"Epoch : {epoch+1} - \"\n",
        "            f\"loss : {epoch_loss:.4f} - acc: {epoch_accuracy:.4f} - \"\n",
        "            f\"val_loss : {epoch_val_loss:.4f} - val_acc: {epoch_val_accuracy:.4f}\\n\"\n",
        "        )\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    return train_acc_list, val_acc_list, train_loss_list, val_loss_list\n"
      ]
    }
  ]
}